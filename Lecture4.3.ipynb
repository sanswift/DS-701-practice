{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from collections import Counter\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you need to implement your own K Means algorithm. Please follow the instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(X, k, max_iter=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - X : feature matrix, np.array\n",
    "    - k : number of clusters\n",
    "    - max_iter : maximum iteratations\n",
    "\n",
    "    Returns:\n",
    "    - centers: k centers\n",
    "    - labels: labels assigned for each data point\n",
    "    \"\"\"\n",
    "    \n",
    "    # randomly choose k points as initialized centers\n",
    "    # convert each center to tuple type\n",
    "    centers_ind = np.random.choice(range(X.shape[0]), size=k)\n",
    "    centers = X[centers_ind]\n",
    "    \n",
    "    # loop max_iter\n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        \n",
    "        ################ Step 1: Assignment ################\n",
    "        # compute distances between X and centers, using pairwise distance\n",
    "        distances = euclidean_distances(X, centers)\n",
    "        \n",
    "        # get labels of each data point\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        \n",
    "        ################ Step 2: Compute New Centers ################\n",
    "        # get new centers\n",
    "        new_centers = centers.copy()\n",
    "        for i in range(len(centers)):\n",
    "            \n",
    "            # find data points with center i\n",
    "            data = X[np.where(labels == i)]\n",
    "            \n",
    "            # update each center by averaging data\n",
    "            new_centers[i] = np.mean(data, axis=0)\n",
    "        \n",
    "        \n",
    "        ################ Step 3: Check Convergence ################\n",
    "        # compute distance between new centers and old centers, using pairwise distance\n",
    "        mat = euclidean_distances(new_centers, centers)\n",
    "        \n",
    "        # sum up diagonal values\n",
    "        error = np.sum([mat[i,i] for i in range(len(mat))])\n",
    "        \n",
    "        # if error is less than 1e-6, break\n",
    "        if error < 1e-6:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        ################ Step 4: Update Centers ################\n",
    "        centers = new_centers\n",
    "    \n",
    "    return centers, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "road_network = []\n",
    "\n",
    "with open(\"../data/spatial_network.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        \n",
    "        # split by comma, only get LONGITUDE and LATITUDE, then convert to float\n",
    "        record = list(map(float, line.strip().split(',')[1:3]))\n",
    "        \n",
    "        # append to road_network\n",
    "        road_network.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(road_network)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# YOUR OWN MODEL\n",
    "centers, labels = k_means(X, k=3, max_iter=100)\n",
    "\n",
    "# SKLEARN MODEL\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(X)\n",
    "centers_sklearn, labels_sklearn = kmeans.cluster_centers_, kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for the data\n",
    "assert X.shape == (434874, 2)\n",
    "assert round(X[666,1],4) == 56.6474\n",
    "\n",
    "# test for k means algorithm\n",
    "assert round(centers[0][0],4) == 8.7975\n",
    "assert round(centers[0][1],4) == 56.8675\n",
    "assert labels[111111] == 2\n",
    "assert labels[222222] == 1\n",
    "assert labels[333333] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [labels, labels_sklearn]\n",
    "TITLES = [\"YOUR OWN MODEL\", \"SCIKIT-LEARN\"]\n",
    "\n",
    "# it might take seconds to run\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(2,1,i+1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=LABELS[i], cmap='viridis')\n",
    "    plt.xlabel(\"LONGITUDE\")\n",
    "    plt.ylabel(\"LATITUDE\")\n",
    "    plt.title(\"Clustering by %s\"%TITLES[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(centers, labels):\n",
    "    \"\"\"Sum squared euclidean distance of all points to their cluster center\"\"\"\n",
    "    \n",
    "    res = 0\n",
    "    # loop each label\n",
    "    for label in set(labels):\n",
    "        \n",
    "        # get center\n",
    "        c = centers[label].reshape(1,-1)\n",
    "        \n",
    "        # get data points\n",
    "        pts = X[np.where(labels==label)]\n",
    "        \n",
    "        # compute sum of square error\n",
    "        ss = euclidean_distances(c, pts).sum()\n",
    "        \n",
    "        # add to result\n",
    "        res += ss\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def plot_k_sse(X, min_k, max_k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - X : feature matrix, \n",
    "    - min_k, max_k : smallest and largest k to plot sse for\n",
    "    \"\"\"\n",
    "    k_values = range(min_k, max_k+1)\n",
    "    sse_values = []\n",
    "    for k in k_values:\n",
    "        # train k means model\n",
    "        centers, labels = k_means(X, k=k)\n",
    "        # compute sse\n",
    "        SSE = sse(centers, labels)\n",
    "        print (k, \": \", int(SSE))\n",
    "        # append to list\n",
    "        sse_values.append(SSE)\n",
    "    # plot\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_values, sse_values)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('sum squared error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "plot_k_sse(X, 2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_silhouette(X, min_k, max_k):\n",
    "    \"\"\"Plots sse for values of k between min_k and max_k\n",
    "\n",
    "    Args:\n",
    "    - X : feature matrix\n",
    "    - min_k, max_k : smallest and largest k to plot sse for\n",
    "    \"\"\"\n",
    "    k_values = range(min_k, max_k+1)\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        # train model\n",
    "        centers, labels = k_means(X, k=k)\n",
    "        # compute score, with sampling\n",
    "        score = silhouette_score(X, labels, sample_size = 10000)\n",
    "        print (k, \": \", score)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_values, silhouette_scores)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('silhouette score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "plot_k_silhouette(X, 2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gap Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/milesgranger/gap_statistic/blob/master/gap_statistic/optimalK.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gap_statistic import OptimalK\n",
    "\n",
    "optimalK = OptimalK(parallel_backend=None)\n",
    "optimalK(X, cluster_array=range(2,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to leverage [Scipy](http://www.scipy.org/) to perform [hierarchical clustering](http://en.wikipedia.org/wiki/Hierarchical_clustering) using `New York Times articles`.\n",
    "\n",
    "1. Hierarchical clustering is more computationally intensive than Kmeans.  Also it is hard to visualize the results of a hierarchical clustering if you have too much data (since it represents its clusters as a tree).   \n",
    "\n",
    "2. The first step to using `scipy's` Hierarchical clustering is to first find out how similar our vectors are to one another. To do this we use the `euclidean distances` to compute a similarity matrix of our data (pairwise distances). \n",
    "\n",
    "3. Now that we have a square similarity matrix we can start to cluster!  Pass this matrix into scipy's `linkage` [function](http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html) to compute our hierarchical clusters.\n",
    "\n",
    "4. We in theory have all the information about our clusters but it is basically impossible to interpret in a sensible manner.  Thankfully scipy also has a function to visualize this madness.  Using scipy's `dendrogram` [function](http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html) plot the linkages as a hierachical tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "articles_df = pd.read_csv(\"../data/articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(articles_df['content'])\n",
    "\n",
    "\n",
    "# Distance Matrix\n",
    "dist_mat = euclidean_distances(X.todense(), X.todense())\n",
    "\n",
    "\n",
    "# Linkage\n",
    "link = linkage(dist_mat, method='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dendrogram plot\n",
    "plt.figure(figsize=(16,8))\n",
    "dendro = dendrogram(link, color_threshold=2.01, leaf_font_size=9,\n",
    "                    labels=small_df['section_name'].values)\n",
    "plt.ylim(1,2.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative Hierarchical Clustering in Scikit-Learn.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X = np.array(road_network)\n",
    "dbscan = DBSCAN(eps=0.01, min_samples=2).fit(X)\n",
    "labels_dbscan = dbscan.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels_dbscan, cmap='viridis')\n",
    "plt.xlabel(\"LONGITUDE\")\n",
    "plt.ylabel(\"LATITUDE\")\n",
    "plt.title(\"Clustering by DBSCAN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
