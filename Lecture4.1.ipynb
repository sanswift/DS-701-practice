{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps you understand k nearest neighbor and naive bayes in details. Following the instructions, you will be able to complete your own models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test data\n",
    "X_train = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2], [-1, -2]])\n",
    "y_train = np.array([1,1,1,0,0,0,1])\n",
    "X_test = np.array([[1, 0], [-2, -2], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# implement your own knn classifier\n",
    "\n",
    "class KNNClassifier(object):\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # just initialize x and y\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _distance(self, data1, data2):\n",
    "        \"\"\"Manhattan Distance\"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return \n",
    "\n",
    "    def _predict_one(self, test):\n",
    "        \"\"\"predict a single sample\"\"\"\n",
    "        \n",
    "        # zip X and y together, for each x in X, calculate distance between x and test\n",
    "        # combine the distance and y as a tuple, then sort the list of tuple\n",
    "        # YOUR CODE HERE\n",
    "        distances = \n",
    "        \n",
    "        # choose top k\n",
    "        # YOUR CODE HERE\n",
    "        top_k = \n",
    "        \n",
    "        # get corresponding y list\n",
    "        # YOUR CODE HERE\n",
    "        y_list = \n",
    "        \n",
    "        # get the majority category\n",
    "        # YOUR CODE HERE\n",
    "        y_pred = \n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # predict all samples, return an array\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your KNN Classifier\n",
    "knn = KNNClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_you = knn.predict(X_test)\n",
    "\n",
    "# From sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_sklearn = KNeighborsClassifier()\n",
    "knn_sklearn.fit(X_train, y_train)\n",
    "y_pred_sklearn = knn_sklearn.predict(X_test)\n",
    "\n",
    "# The results should be the same, [0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data can be downloaded from UCI machine learning repository. https://archive.ics.uci.edu/ml/machine-learning-databases/00219/.\n",
    "* bdworld.zip\n",
    "* We choose **.arff** file in **weka** folder. (dbworld_bodies_stemmed.arff and dbworld_subjects_stemmed.arff)\n",
    "* **scipy.io.arff.loadarff** is a method to read .arff file. https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.arff.loadarff.html\n",
    "* Please write a function to read and process arff file, satisfying \n",
    "    * return data and column names\n",
    "    * Each element in data is the type of int (either int32,int64 or any other based on your computer)\n",
    "* You should pass all the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_arff(arff_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: the directory path of arff file\n",
    "    output: data, feature name\n",
    "    \"\"\"\n",
    "    \n",
    "    # use loadarff method to get data and meta\n",
    "    # YOUR CODE HERE\n",
    "    data, meta = \n",
    "    \n",
    "    # convert each element into int\n",
    "    # YOUR CODE HERE\n",
    "    arr = \n",
    "    \n",
    "    # get column names\n",
    "    # YOUR CODE HERE\n",
    "    columns = \n",
    "    \n",
    "    # return data(array of arrays), column names(array)\n",
    "    return arr, columns\n",
    "\n",
    "# please change to your own work directory, if differs\n",
    "bodies_data, bodies_columns = process_arff(\"../data/dbworld_bodies_stemmed.arff\")\n",
    "subjects_data, subjects_columns = process_arff(\"../data/dbworld_subjects_stemmed.arff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for process_arff function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for dataframe\n",
    "assert type(bodies_data) == np.ndarray\n",
    "assert type(bodies_data[0]) == np.ndarray\n",
    "assert type(subjects_data) == np.ndarray\n",
    "assert type(subjects_data[0]) == np.ndarray\n",
    "\n",
    "# test for dimension\n",
    "assert bodies_data.shape == (64, 3722)\n",
    "assert subjects_data.shape == (64, 230)\n",
    "\n",
    "# test for column name\n",
    "assert bodies_columns[666] == 'comunicazion'\n",
    "assert subjects_columns[111] == 'invoc'\n",
    "\n",
    "# test for value type\n",
    "assert np.issubdtype(type(bodies_data[0,0]), np.integer)\n",
    "assert np.issubdtype(type(subjects_data[0,0]), np.integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you should write your own Naive Bayes model to predict whether an email is spam or not. Each column has two categories, 0 and 1, thus it is a Bernoulli Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliNaiveBayes(object):\n",
    "    \n",
    "    def __init__(self, alpha=1.0):\n",
    "        \n",
    "        # laplace smoothing parameter\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # number of samples\n",
    "        # YOUR CODE HERE\n",
    "        n_sample = \n",
    "        \n",
    "        # separate X by unique categories in y\n",
    "        # obtain a list containing two 2-d arrays\n",
    "        # YOUR CODE HERE\n",
    "        separated = \n",
    "        \n",
    "        # compute log prior probability of y\n",
    "        # YOUR CODE HERE\n",
    "        self.log_prior = \n",
    "        \n",
    "        # compute likelihood\n",
    "        # total counts of each feature among emails in each category of y\n",
    "        # YOUR CODE HERE\n",
    "        count = \n",
    "        \n",
    "        # total number of emails in each category of y\n",
    "        # YOUR CODE HERE\n",
    "        n_doc = \n",
    "        \n",
    "        # compute log probability distribution of each feature, given y\n",
    "        # YOUR CODE HERE\n",
    "        # feature=1\n",
    "        self.feature_1_log_prob = \n",
    "        # feature=0\n",
    "        self.feature_0_log_prob = \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \n",
    "        # store prediction results of each x in X\n",
    "        res = []\n",
    "        \n",
    "        # for every new instance, make prediction\n",
    "        for x in X:\n",
    "            \n",
    "            # first compute log likelihood\n",
    "            # YOUR CODE HERE\n",
    "            ll = \n",
    "            \n",
    "            # add log prior to ll\n",
    "            # YOUR CODE HERE\n",
    "            prediction = \n",
    "            \n",
    "            # append to res\n",
    "            res.append(prediction)\n",
    "        \n",
    "        return res\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # predict the label corresponding to the larger log probability\n",
    "        # YOUR CODE HERE\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y from data using columns\n",
    "# The label is \"CLASS\"\n",
    "\n",
    "def split_Xy(data, columns):\n",
    "    \n",
    "    # get the index of CLASS\n",
    "    # YOUR CODE HERE\n",
    "    class_ind = \n",
    "    \n",
    "    # get y\n",
    "    # YOUR CODE HERE\n",
    "    y = \n",
    "    \n",
    "    # get X\n",
    "    # YOUR CODE HERE\n",
    "    X = \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for split_Xy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb, yb = split_Xy(bodies_data, bodies_columns)\n",
    "Xs, ys = split_Xy(subjects_data, subjects_columns)\n",
    "\n",
    "assert Xb.shape == (64, 3721)\n",
    "assert Xb.sum(axis=0)[2] == 4\n",
    "\n",
    "assert yb.shape == (64,)\n",
    "assert yb[-5] == 1\n",
    "assert yb.sum() == 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# function to train model\n",
    "\n",
    "def train_model(X, y, test_size=0.3, random_state=42):\n",
    "    \n",
    "    # split train and test\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # initialize a Bernoulli Naive Bayes\n",
    "    # YOUR CODE HERE\n",
    "    bnb =\n",
    "    \n",
    "    \n",
    "    # fit model on training set\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # predict on test set\n",
    "    # YOUR CODE HERE\n",
    "    y_pred = \n",
    "    \n",
    "    # confusion matrix\n",
    "    # YOUR CODE HERE\n",
    "    cm = \n",
    "    \n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for train_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_b = train_model(Xb, yb)\n",
    "cm_s = train_model(Xs, ys)\n",
    "\n",
    "assert cm_b[0,0] == 12\n",
    "assert cm_b[0,1] == 3\n",
    "assert cm_b[1,0] == 0\n",
    "\n",
    "assert cm_s[0,0] == 11\n",
    "assert cm_s[0,1] == 1\n",
    "assert cm_s[1,0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is better, bodies text or subjects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two boxes with different color balls. Box1 has 3 blues, 1 yellow and 1 green. Box2 has 2 blues, 3 yellow and 2 green. Uniformly get a ball from one of the two boxes, and the color is green. Now reach into that same box second time. What is the probability that the second ball is blue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./BN.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue 1\n",
    "# Green 2\n",
    "# Yellow 3\n",
    "# YOUR CODE HERE\n",
    "box1 = [1,1,1,2,3]\n",
    "box2 = [1,1,2,2,3,3,3]\n",
    "\n",
    "# random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Monte Carlo Simulation results \n",
    "res = []\n",
    "\n",
    "# run 1000 MC simulations\n",
    "for _ in range(1000):\n",
    "    \n",
    "    tmp = []\n",
    "    \n",
    "    # for each MC simulation, sampling 200 times\n",
    "    for i in range(200):\n",
    "        \n",
    "        # uniformly random pick a box\n",
    "        # YOUR CODE HERE\n",
    "        box = \n",
    "        \n",
    "        # if box1\n",
    "        if box >= 0.5:\n",
    "            # generate two balls (array of two values) from Box 1\n",
    "            # YOUR CODE HERE\n",
    "            balls = \n",
    "            # append balls to tmp\n",
    "            tmp.append(balls)\n",
    "        # if box2\n",
    "        else:\n",
    "            # generate two balls (array of two values) from Box 2\n",
    "            # YOUR CODE HERE\n",
    "            balls = \n",
    "            # append balls to tmp\n",
    "            tmp.append(balls)\n",
    "\n",
    "    # ball 1 is Green (=2), so let's filter out some samples\n",
    "    # YOUR CODE HERE\n",
    "    filtered = \n",
    "\n",
    "    # probability of ball2 is blue, given ball1 is green\n",
    "    # YOUR CODE HERE\n",
    "    p = \n",
    "    \n",
    "    res.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(res, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = 0.5076213763093029\n",
    "\n",
    "You can increase the number of simulation to get a more precise value, but it will cost much running time. You can also try different distributions in each box, to see how the probability changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
